{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Process Predictions\n",
    "Optimize keypoint position s.t. a set of constraints using Projected Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning_pose.postprocess.projected_gd import ProjectedGD\n",
    "from torchtyping import TensorType\n",
    "from omegaconf import DictConfig\n",
    "from lightning_pose.utils.scripts import get_imgaug_transform, get_dataset, get_data_module, get_loss_factories\n",
    "from lightning_pose.utils.io import return_absolute_data_paths\n",
    "import hydra\n",
    "import os\n",
    "import pandas as pd\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(preds: TensorType[\"num_samples\", \"num_keypoints\",2],\n",
    "        gt: TensorType[\"num_samples\", \"num_keypoints\",2]):\n",
    "    bp_error = torch.linalg.norm(preds - gt, dim=2) # error per keypoint-frame\n",
    "    #average_error = torch.mean(bp_error, dim=1) # mean over keypoints\n",
    "    return bp_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_config(config_dir: str, config_name: str) -> DictConfig:\n",
    "    assert(os.path.isdir(config_dir))\n",
    "    hydra.initialize_config_dir(base_config_dir)\n",
    "    cfg = hydra.compose(config_name=\"config\")\n",
    "    return cfg\n",
    "from typing import List\n",
    "def get_keypoint_names(csv_data: pd.DataFrame, header_rows: List[int]) -> List[str]:\n",
    "    if header_rows == [0,1,2]:\n",
    "        keypoint_names = [c[1] for c in csv_data.columns[1::2]]\n",
    "    elif header_rows == [1,2]:\n",
    "        keypoint_names = [c[0] for c in csv_data.columns[1::2]]\n",
    "    return keypoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"rick-configs-1\"\n",
    "# dataset_name = \"ibl-pupil-2\"\n",
    "# dataset_name = \"ibl-paw-2\"\n",
    "base_config_dir = \"/home/jovyan/rick-configs-1\"\n",
    "base_save_dir = \"/home/jovyan/\"\n",
    "\n",
    "# hydra.initialize_config_dir(base_config_dir)\n",
    "# cfg = hydra.compose(config_name=\"config\")\n",
    "cfg = get_base_config(base_config_dir, \"config\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth labels\n",
    "csv_file = os.path.join(cfg.data.data_dir, cfg.data.csv_file)\n",
    "csv_data = pd.read_csv(csv_file, header=list(cfg.data.header_rows))\n",
    "keypoints_gt = csv_data.iloc[:, 1:].to_numpy().reshape(csv_data.shape[0], -1, 2)\n",
    "\n",
    "keypoint_names = get_keypoint_names(csv_data, cfg.data.header_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1045, 17, 2)\n"
     ]
    }
   ],
   "source": [
    "# load pca singleview preds\n",
    "pred_file = \"/home/jovyan/lightning-pose/multirun/2022-03-27/01-17-25/0/predictions.csv\"\n",
    "pred_df = pd.read_csv(pred_file, header=[0, 1, 2], index_col=0)\n",
    "if pred_df.keys()[-1][0] == \"set\":\n",
    "    # these are predictions on labeled data; get rid of last column that\n",
    "    # contains info about train/val/test set\n",
    "    is_video = False\n",
    "    tmp = pred_df.iloc[:, :-1].to_numpy().reshape(pred_df.shape[0], -1, 3)\n",
    "keypoints_pred = tmp[:, :, :2]  # shape (samples, n_keypoints, 2)\n",
    "confidences = tmp[:, :, -1]  # shape (samples, n_keypoints)\n",
    "print(keypoints_pred.shape)\n",
    "#ground_truth_df = pd.read_csv(\"/datastores/mouseRunningData/CollectedData_.csv\", header=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled images in the full dataset (train+val+test): 1045\n",
      "Size of -- train set: 75, val set: 104, test set: 105\n",
      "Warning: the argument `seed` shadows a Pipeline constructor argument of the same name.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[/opt/dali/dali/operators/reader/loader/video_loader.h:177] ``file_list_include_preceding_frame`` is set to False (or not set at all). In future releases, the default behavior would be changed to True.\n",
      "[/opt/dali/dali/operators/reader/nvdecoder/nvdecoder.cc:82] Warning: Decoding on a default stream. Performance may be affected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled images in the full dataset (train+val+test): 1045\n",
      "Size of -- train set: 75, val set: 104, test set: 105\n",
      "Results of running PCA (pca_singleview) on keypoints:\n",
      "Kept 13/28 components, and found:\n",
      "Explained variance ratio: [0.374 0.198 0.182 0.101 0.054 0.029 0.02  0.011 0.008 0.005 0.005 0.004\n",
      " 0.003 0.002 0.002 0.001 0.001 0.001 0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.   ]\n",
      "Variance explained by 13 components: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/lightning-pose/lightning_pose/losses/losses.py:296: UserWarning: Using empirical epsilon=0.173 * multiplier=1.000 -> total=0.173 for pca_singleview loss\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# save_dir = os.path.join(base_save_dir, dataset_name)\n",
    "save_dir = \"/home/jovyan/lightning-pose\"\n",
    "\n",
    "loss_type = \"pca_singleview\" # Change for different loss functions\n",
    "error_metric = \"reprojection_error\" # for pca only\n",
    "# define models\n",
    "to_compute = \"rmse\" # rmse | pca_multiview | pca_singleview | unimodal_mse\n",
    "model_name = \"supervised-heatmap-75\"\n",
    "train_frames = 75 # 000\n",
    "#pca_singleview_epsilon = 15.\n",
    "#pca_multiview_epsilon = None\n",
    "#empirical_epsilon_multiplier = 1.0 # can hack this if want to sweep over multipliers/losses\n",
    "model_type = \"heatmap\"\n",
    "#rng_seed = 42\n",
    "# temporal_epsilon = 9.8 # hack for now\n",
    "#loss_weight_dict['pca_singleview'].sort(reverse=True)\n",
    "\n",
    "pca_loss = None\n",
    "datamodule = None\n",
    "model_cfg = cfg.copy()\n",
    "model_cfg.training.train_frames = train_frames\n",
    "model_cfg.model.losses_to_use = [loss_type]\n",
    "from lightning_pose.utils.pca import KeypointPCA\n",
    "data_dir, video_dir = return_absolute_data_paths(data_cfg=model_cfg.data)\n",
    "imgaug_transform = get_imgaug_transform(cfg=model_cfg)\n",
    "dataset = get_dataset(cfg=model_cfg, data_dir=data_dir, imgaug_transform=imgaug_transform)\n",
    "data_module = get_data_module(cfg=model_cfg, dataset=dataset, video_dir=video_dir)\n",
    "data_module.setup()\n",
    "# compute pca params\n",
    "loss_factories = get_loss_factories(cfg=model_cfg, data_module=data_module)\n",
    "pca_loss = loss_factories[\"unsupervised\"].loss_instance_dict[loss_type]\n",
    "# store results here\n",
    "if to_compute == \"pca_singleview\":\n",
    "    # remove obstacle keypoints\n",
    "    keypoint_names = [kp for kp in keypoint_names if kp not in ['obs_top','obsHigh_bot','obsLow_bot']]\n",
    "    print(keypoint_names)\n",
    "\n",
    "metrics_collected = {bp: [] for bp in keypoint_names}\n",
    "cols_collected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightning_pose.utils.pca.KeypointPCA at 0x7f51909fc1f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_loss.pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_keypoints(cfg, keypoints_pred):\n",
    "    \"\"\"reshape to training dims for pca losses, which are optimized for these dims\"\"\"\n",
    "    x_resize = cfg.data.image_resize_dims.width\n",
    "    x_og = cfg.data.image_orig_dims.width\n",
    "    keypoints_pred[:, :, 0] = keypoints_pred[:, :, 0] * (x_resize / x_og)\n",
    "    # put y vals back in original pixel space\n",
    "    y_resize = cfg.data.image_resize_dims.height\n",
    "    y_og = cfg.data.image_orig_dims.height\n",
    "    keypoints_pred[:, :, 1] = keypoints_pred[:, :, 1] * (y_resize / y_og)\n",
    "    return keypoints_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize both arrays to training dims\n",
    "keypoints_pred = resize_keypoints(model_cfg, keypoints_pred)\n",
    "keypoints_gt = resize_keypoints(model_cfg, keypoints_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant keypoints for pca singleview\n",
    "#pca_cols = pca_loss.pca.columns_for_singleview_pca\n",
    "keypoints_pred = pca_loss.pca._format_data(data_arr=torch.tensor(keypoints_pred).reshape(keypoints_pred.shape[0], -1))\n",
    "keypoints_gt = pca_loss.pca._format_data(data_arr=torch.tensor(keypoints_gt).reshape(keypoints_gt.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1045, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_gd = ProjectedGD(data=keypoints_pred.to(\"cuda\", dtype=pca_loss.pca.parameters[\"mean\"].dtype), \\\n",
    "    ground_truth=keypoints_gt.to(\"cuda\", dtype=pca_loss.pca.parameters[\"mean\"].dtype), \\\n",
    "    proj_params={\"pca_singleview\": pca_loss.pca}, lr=None, max_iter=4000, tol=1e-3, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:05<00:00, 673.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "out = proj_gd.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list = [err.unsqueeze(-1) for err in proj_gd.error_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1045, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.hstack(err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "mean = np.mean(out, axis=0)\n",
    "stderr = np.std(out, axis=0) / np.sqrt(out.shape[0])\n",
    "plt.plot(np.mean(out, axis=0))\n",
    "plt.fill_between(np.arange(len(mean)), mean - stderr, mean + stderr, alpha=0.5)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('mean pixel error -+ stderr')\n",
    "save_dir = \"/home/jovyan\"\n",
    "plt.title(\"Pixel error during optimization\")\n",
    "plt.savefig(os.path.join(save_dir, \"pca_singleview_error_vs_iter.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [ 3.1426055,  3.1426055,  3.1426055, ...,  3.1426055,  3.1426055,\n",
       "         3.1426055],\n",
       "       [11.278218 , 11.278218 , 11.278218 , ..., 14.035965 , 14.035965 ,\n",
       "        14.035965 ],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 66.7442,  37.7990],\n",
       "         [162.8132,  67.4593],\n",
       "         [151.7117,  61.4233],\n",
       "         ...,\n",
       "         [ 58.4374, 204.5468],\n",
       "         [ 34.3833, 210.4543],\n",
       "         [245.2683, 177.6950]],\n",
       "\n",
       "        [[ 37.3207,  77.2357],\n",
       "         [177.8746,  58.4439],\n",
       "         [176.0794,  73.8363],\n",
       "         ...,\n",
       "         [ 39.8484, 195.9745],\n",
       "         [ 22.2865, 200.0844],\n",
       "         [245.2894, 177.2753]],\n",
       "\n",
       "        [[ 93.2913,  73.8146],\n",
       "         [209.0615,  66.3784],\n",
       "         [184.7010,  68.9636],\n",
       "         ...,\n",
       "         [ 54.1263, 216.9473],\n",
       "         [ 33.1530, 236.7531],\n",
       "         [245.7558, 181.3655]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[106.7211,  66.0126],\n",
       "         [208.4263,  59.0834],\n",
       "         [145.7761,  66.3464],\n",
       "         ...,\n",
       "         [ 59.8686, 142.2760],\n",
       "         [ 42.8180, 121.8896],\n",
       "         [245.1495, 179.7290]],\n",
       "\n",
       "        [[136.4247,  66.2763],\n",
       "         [164.1049,  73.7205],\n",
       "         [165.4491,  68.3267],\n",
       "         ...,\n",
       "         [ 63.1628, 140.2260],\n",
       "         [ 43.1016, 122.2235],\n",
       "         [243.9804, 178.1428]],\n",
       "\n",
       "        [[ 94.2892,  70.6250],\n",
       "         [202.1082,  78.7779],\n",
       "         [134.5277,  70.7692],\n",
       "         ...,\n",
       "         [ 64.8049, 143.3832],\n",
       "         [ 52.7272, 125.5274],\n",
       "         [243.9054, 179.2536]]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY version\n",
    "* use norm on desired axis/dims. \n",
    "* reshape to go between per bodypart and per frame\n",
    "* have to reshape differently just to be able to work with 2d mats always and not tensors\n",
    "* 2d keypoints can be treated independently for the objective\n",
    "* we just have to reshape them back to num_frames x num_keypoints for the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   0.   2.]\n",
      " [  0.  10.   0.  20.]\n",
      " [  0. 100.   0. 200.]]\n"
     ]
    }
   ],
   "source": [
    "test_arr = np.array([[0., 1., 0., 2], [0., 10., 0., 20.], [0., 100., 0., 200.]])\n",
    "print(test_arr)\n",
    "test_arr1 = test_arr.reshape(test_arr.shape[0], -1, 2)\n",
    "test_arr_2 = test_arr.reshape(-1,2)\n",
    "# can reshape directly to test_arr_2\n",
    "assert(np.allclose(test_arr_2[1,:], test_arr[0, 2:]))\n",
    "test_arr_3 = test_arr_2.reshape(test_arr.shape)\n",
    "assert(np.allclose(test_arr_3, test_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14630, 2)\n"
     ]
    }
   ],
   "source": [
    "keypoints_pred = keypoints_pred.detach().cpu().numpy()\n",
    "keypoints_pred_2d = keypoints_pred.reshape(-1, 2) # shape (samples* n_keypoints, 2)\n",
    "print(keypoints_pred_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pca params to numpy\n",
    "pca_param_np = {}\n",
    "for p_name, p_val in pca_loss.pca.parameters.items():\n",
    "    if isinstance(p_val, torch.Tensor):\n",
    "        pca_param_np[p_name] = p_val.detach().cpu().numpy()\n",
    "    else:\n",
    "        pca_param_np[p_name] = p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean', 'kept_eigenvectors', 'discarded_eigenvectors', 'epsilon'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_param_np.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_cvxpy(keypoints, evecs, mean):\n",
    "    mean = np.tile(mean, (keypoints.shape[0], 1)) # for each sample, repeat mean, to broadcast\n",
    "    # transform data into low-d space as in scikit learn's _BasePCA.transform()\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/37ac6788c9504ee409b75e5e24ff7d86c90c2ffb/sklearn/decomposition/_base.py#L97\n",
    "    centered_data = keypoints - mean\n",
    "    low_d_projection = centered_data @ evecs.T\n",
    "\n",
    "    # project back up to observation space, as in scikit learn's _BasePCA.inverse_transform()\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/37ac6788c9504ee409b75e5e24ff7d86c90c2ffb/sklearn/decomposition/_base.py#L125\n",
    "    reprojection = low_d_projection @ evecs + mean\n",
    "    return reprojection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cp.Variable(keypoints_pred_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14630,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.ones(shape=(keypoints_pred_2d.shape[0],))\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = cp.norm(x - keypoints_pred_2d, p=2, axis=1)\n",
    "# sum the weighted norms over the samples and keypoints\n",
    "objective = cp.Minimize(cp.sum(cp.multiply(weights, norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expression(AFFINE, UNKNOWN, (1045, 28))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "cp.reshape(x, shape=keypoints_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_param_np[\"mean\"].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expression(AFFINE, UNKNOWN, (1045, 28))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.reshape(x, shape=keypoints_pred.shape) - np.tile(pca_param_np[\"mean\"], (keypoints_pred.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expression(AFFINE, UNKNOWN, (1045, 28))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction = reproject_cvxpy(cp.reshape(x, shape=keypoints_pred.shape), \\\n",
    "pca_param_np[\"kept_eigenvectors\"], \\\n",
    "pca_param_np[\"mean\"])\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_cvxpy(keypoints, evecs, mean):\n",
    "    mean = np.tile(mean, (keypoints.shape[0], 1)) # for each sample, repeat mean, to broadcast\n",
    "    # transform data into low-d space as in scikit learn's _BasePCA.transform()\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/37ac6788c9504ee409b75e5e24ff7d86c90c2ffb/sklearn/decomposition/_base.py#L97\n",
    "    centered_data = keypoints - mean\n",
    "    low_d_projection = centered_data @ evecs.T\n",
    "\n",
    "    # project back up to observation space, as in scikit learn's _BasePCA.inverse_transform()\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/37ac6788c9504ee409b75e5e24ff7d86c90c2ffb/sklearn/decomposition/_base.py#L125\n",
    "    reprojection = low_d_projection @ evecs + mean\n",
    "    return reprojection\n",
    "    \n",
    "def build_pca_constraint(x: cp.Variable, keypoints_orig_shape: Tuple[int,int], pca_param_np: Dict[str, np.array]) -> List[cp.constraints.Inequality]:\n",
    "    # reshape keypoints \n",
    "    x = cp.reshape(x, shape=(keypoints_orig_shape))\n",
    "    # transform data into low-d space as in scikit learn's _BasePCA.transform()\n",
    "    reconstruction = reproject_cvxpy(x, pca_param_np[\"kept_eigenvectors\"], pca_param_np[\"mean\"])\n",
    "    recon_err = cp.norm(reconstruction - x, p=2, axis=1)\n",
    "    return [recon_err <= pca_param_np[\"epsilon\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_pca_constraint(x=x, keypoints_orig_shape=keypoints_pred.shape, pca_param_np=pca_param_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value 1109126.681664947\n",
      "Optimal var\n",
      "[[ 29.67382706  42.76322705]\n",
      " [114.49743788 114.35193252]\n",
      " [116.3916312  103.10968368]\n",
      " ...\n",
      " [ 37.16423818 203.85214501]\n",
      " [  5.32008838 179.88870272]\n",
      " [ 24.11000905 194.07364763]]\n"
     ]
    }
   ],
   "source": [
    "keypoints_pred_2d = keypoints_pred.reshape(-1, 2) # shape (samples* n_keypoints, 2)\n",
    "\n",
    "x = cp.Variable(keypoints_pred_2d.shape)\n",
    "weights = np.ones(shape=(keypoints_pred_2d.shape[0],)) # in the future use actual vals\n",
    "\n",
    "norm = cp.norm(x - keypoints_pred_2d, p=2, axis=1)\n",
    "# sum the weighted norms over the samples and keypoints\n",
    "objective = cp.Minimize(cp.sum(cp.multiply(weights, norm)))\n",
    "\n",
    "constraints = build_pca_constraint(x=x, keypoints_orig_shape=keypoints_pred.shape, pca_param_np=pca_param_np)\n",
    "\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "print(\"Optimal value\", prob.solve())\n",
    "print(\"Optimal var\")\n",
    "print(x.value) # A numpy ndarray.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_keypoints = x.value.reshape(keypoints_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_keypoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8782, -1.8782, -1.8782,  ..., -1.8953, -1.8953, -1.8953],\n",
       "         [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8782, -1.8782],\n",
       "         [-1.8782, -1.8782, -1.8782,  ..., -1.8782, -1.8610, -1.8610],\n",
       "         ...,\n",
       "         [-1.7412, -1.7754, -1.7754,  ..., -1.8268, -1.8439, -1.8439],\n",
       "         [-1.7412, -1.7754, -1.7754,  ..., -1.8097, -1.8268, -1.8439],\n",
       "         [-1.7412, -1.7754, -1.7754,  ..., -1.8097, -1.8268, -1.8439]],\n",
       "\n",
       "        [[-1.7906, -1.7906, -1.7906,  ..., -1.8081, -1.8081, -1.8081],\n",
       "         [-1.7906, -1.7906, -1.7906,  ..., -1.7906, -1.7906, -1.7906],\n",
       "         [-1.7906, -1.7906, -1.7906,  ..., -1.7906, -1.7731, -1.7731],\n",
       "         ...,\n",
       "         [-1.6506, -1.6856, -1.6856,  ..., -1.7381, -1.7556, -1.7556],\n",
       "         [-1.6506, -1.6856, -1.6856,  ..., -1.7206, -1.7381, -1.7556],\n",
       "         [-1.6506, -1.6856, -1.6856,  ..., -1.7206, -1.7381, -1.7556]],\n",
       "\n",
       "        [[-1.5604, -1.5604, -1.5604,  ..., -1.5779, -1.5779, -1.5779],\n",
       "         [-1.5604, -1.5604, -1.5604,  ..., -1.5604, -1.5604, -1.5604],\n",
       "         [-1.5604, -1.5604, -1.5604,  ..., -1.5604, -1.5430, -1.5430],\n",
       "         ...,\n",
       "         [-1.4210, -1.4559, -1.4559,  ..., -1.5081, -1.5256, -1.5256],\n",
       "         [-1.4210, -1.4559, -1.4559,  ..., -1.4907, -1.5081, -1.5256],\n",
       "         [-1.4210, -1.4559, -1.4559,  ..., -1.4907, -1.5081, -1.5256]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.dataset[0][\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2db7ebd2a6eaabbedad5619cf81ba50362feaaec41f65baf0d1ccad0b63e6ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
